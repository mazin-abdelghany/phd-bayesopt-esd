---
title: "GSD and GP regression - week 5"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
date: "2025-11-13"
---

```{css, echo=FALSE}
#TOC {
    max-width: fit-content;
    white-space: nowrap;
}
  
div:has(> #TOC) {
    display: flex;
    flex-direction: row-reverse;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load required libraries
library(mvtnorm)
library(ggplot2)

# set the seed
set.seed(585883357)
```

# GSD simulations

1. Design a trial, including boundaries
2. Obtain the characteristics of this trial
3. Estimate the expected sample size
4. Modify the sample size to obtain the correct power

The functions needed for the above steps are:

1. `triangular_bounds()`
2. `pocock_bounds()`
3. `of_bounds()`
4. `gsd_simulations()`
5. `ess_simulations()`

## Interval bisection for boundaries

### `gsd_simulations()`

```{r}
gsd_simulations <- function(n_analyses = 3,
                            upper_bounds = c(2.5, 2, 1.5),
                            lower_bounds = c(0, 0.75, 1.5),
                            n_patients = c(20, 40, 60),
                            null_hypothesis = 0,
                            alt_hypothesis = 0.5,
                            variance = 1) {
  
  # sanity checks
  # sanity checks, function stops
  if(length(upper_bounds) != length(lower_bounds)) {
    stop("Warning: number of upper bounds must equal number of lower bounds")
  }
  
  if(length(n_patients) != length(upper_bounds)) {
    stop("Warning: number of patients vector must equal number of bounds")
  }
  
  if(n_analyses != length(upper_bounds)) {
    stop("Warning: number of analyses must equal number of bounds")
  }
  
  # assign values for null and alt hypotheses
  theta_0 <- null_hypothesis
  delta <- alt_hypothesis
  
  # empty mean vectors to fill
  mean_0 <- c()
  mean_1 <- c()
  
  # need to parse the upper and lower boundaries of the design
  # for futility and efficacy, must put the bounds of integration correctly 
  # for pmvnorm
  futility_l_bounds <- list()
  futility_u_bounds <- list()
  efficacy_l_bounds <- list()
  efficacy_u_bounds <- list()

  n_analyses <- length(upper_bounds)

  for (i in 1:n_analyses) {
    
    # special case of i = 1
    if (i == 1) {
      futility_l_bounds[[i]] <- lower_bounds[i]
      futility_u_bounds[[i]] <- upper_bounds[i]
      efficacy_l_bounds[[i]] <- lower_bounds[i]
      efficacy_u_bounds[[i]] <- upper_bounds[i]
      next
    }
    
    # all other cases
    futility_l_bounds[[i]] <- c(lower_bounds[1:i-1], -Inf)
    futility_u_bounds[[i]] <- c(upper_bounds[1:i-1], lower_bounds[i])
    
    efficacy_l_bounds[[i]] <- c(lower_bounds[1:i-1], upper_bounds[i])
    efficacy_u_bounds[[i]] <- c(upper_bounds[1:i-1], Inf)
  }
  
  # list of probabilities to return
  probs_to_return <- list()
  
  # list of SIGMAs
  SIGMA_list <- list()
    
  for (i in 1:n_analyses) {
    if (i == 1) next
    
    # start with diagonal matrix for SIGMA
    SIGMA <- diag(nrow = i)
    
    # n = 2, need to fill all but 11, 22
    # n = 3, need to fill all but 11, 22, 33
    # n = 4, need to fill all but 11, 22, 33, 44
    # etc. 
    for(i in 1:i) {
      for(j  in 1:i) {
        
        # leave the 1s on the diagonal, skip this iteration of for loop
        if(i == j) next
        
        # when i is less than j, the lower number of patients will be in numerator
        if(i < j) SIGMA[i,j] <- sqrt(n_patients[i] / n_patients[j])
        
        # when i is greater than j, the lower number of patients will be in numerator
        if(i > j) SIGMA[i,j] <- sqrt(n_patients[j] / n_patients[i])
        
      }
    }
    
    SIGMA_list[[i]] <- SIGMA
  }
  
  
  for (i in 1:n_analyses) {
    
    ##############
    # ANALYSIS 1 #
    ##############
    if(i == 1) {
      # mean under null
      mean_0[i] <- theta_0 * sqrt(n_patients[i]/(2*variance))
      
      # mean under alternative
      mean_1[i] <- delta * sqrt(n_patients[i]/(2*variance))
      
      # prob stop for futility, null
      futility_null <- pnorm(futility_l_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance))
      
      # prob stop for efficacy, null
      efficacy_null <- pnorm(efficacy_u_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance), 
                             lower.tail = FALSE)
  
      # prob stop for futility, alt
      futility_alt <- pnorm(futility_l_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance))
      
      # prob stop for efficacy
      efficacy_alt <- pnorm(efficacy_u_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance), 
                            lower.tail = FALSE)
      
      probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
      names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
      
      next
    }
    
    ######################
    # ALL OTHER ANALYSES #
    ######################
    
    # next mean under null
    mean_0[i] <- theta_0 * sqrt(n_patients[i] / (2 * variance))
    
    # next mean under alternative
    mean_1[i] <- delta * sqrt(n_patients[i]/ (2*variance))
    
    # bounds for these will be same
    # futility under null
    futility_null <- pmvnorm(lower = futility_l_bounds[[i]], 
                             upper = futility_u_bounds[[i]], 
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    futility_alt <- pmvnorm(lower = futility_l_bounds[[i]], 
                            upper = futility_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    # bounds for these will be same
    # futility under null
    efficacy_null <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                             upper = efficacy_u_bounds[[i]],
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    efficacy_alt <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                            upper = efficacy_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
    names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
    
  }
    
  # vector to collect the sum of futility and efficacy probabilities
  sum_probs <- c()
  
  # get alpha and power
  alpha <- 0
  power <- 0
  
  for (i in 1:n_analyses) {
    
    # pull the probabilities from the list
    tmp_probs <- probs_to_return[[i]]
    
    # gather them into a vector
    # 3:4 because we want to calculate under the alternative
    sum_probs <- c(sum_probs, sum(tmp_probs[3:4]))
    
    alpha <- tmp_probs[2] + alpha
    power <- tmp_probs[4] + power
    
  }
  
  # calculate the expected sample size
  ess <- sum(n_patients * sum_probs)
  vss <- sum(n_patients^2 * sum_probs) - ess^2
  
  # add the expected sample size to the list
  return_values <- append(probs_to_return, values = c(ess, vss, alpha, power))
  
  # name the list
  names_for_list <- as.vector(sapply("analysis_", paste0, 1:n_analyses))
  names_for_list <- c(names_for_list, "expected_sample_size", "var_sample_size",
                      "alpha", "power")
  names(return_values) <- names_for_list
  
  # return probabilities and ESS
  return_values
}
```

### `pocock_bounds_ib()`

Get the bounds using interval bisection.

```{r}
pocock_bounds_ib <- function(n_analyses = 3,
                          alpha = 0.05,
                          n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # starting upper bounds
  ub1 <- rep(0, length.out = n_analyses)
  lb1 <- -ub1
  
  # starting lower bounds
  ub2 <- rep(10, length.out = n_analyses)
  lb2 <- -ub2
  
  # first alpha calculation
  sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = ub1,
                            lower_bounds = lb1,
                            n_patients = n_patients)
  
  while ( abs(sim$alpha - alpha) > epsilon) {
    
    # calculate the first midpoint
    mid_u <- (ub1 + ub2) / 2
    mid_l <- -mid_u 
    
    # calculate the simulated alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = mid_u,
                            lower_bounds = mid_l,
                            n_patients = n_patients)
    
    # 
    if (sim$alpha > alpha) {
      
      ub1 <- mid_u
      lb1 <- mid_l
      
    } else {
      
      ub2 <- mid_u
      lb2 <- mid_l
      
    }
    
  } 
  
  # return the values of interest
  return( list(upper_bounds = ub1, 
               lower_bounds = lb1, 
               simulation = sim) )
  
}
```

```{r, eval=FALSE}
pocock_bounds_ib()
```

### `pocock_bounds()`

Get the bounds with incremental steps.

```{r}
pocock_bounds <- function(n_analyses = 3,
                             alpha = 0.05,
                             n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # close bounds using Bonferroni correction
  # -qnorm because the value of upper bounds must be positive
  bounds <- rep(-qnorm(alpha / n_analyses), length.out = n_analyses)
  
  # set the upper and lower bounds
  upper_bounds <- bounds
  lower_bounds <- -bounds
  
  # get alpha
  sim <- gsd_simulations(n_analyses = n_analyses,
                         upper_bounds = upper_bounds,
                         lower_bounds = lower_bounds,
                         n_patients = n_patients)
  
  # while the absolute value of the difference is larger than the precision
  while(abs(sim$alpha - alpha) >= epsilon) {
    
    # if we are above alpha, increase the magnitude of the bounds
    if( (sim$alpha - alpha) > epsilon) {
      
      bounds <- bounds + abs(sim$alpha - alpha)
  
    # if we are below alpha, decrease the magnitude of the bounds
    } else if ( (sim$alpha - alpha) < epsilon ) {
      
      bounds <- bounds - abs(sim$alpha - alpha)

    }
    
    # save the new bounds
    upper_bounds <- bounds
    lower_bounds <- -bounds
    
    # get the new value of alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                           upper_bounds = upper_bounds,
                           lower_bounds = lower_bounds,
                           n_patients = n_patients)
  }
  
  # return the values of interest
  return( list(upper_bounds = upper_bounds, 
               lower_bounds = lower_bounds, 
               simulation = sim) )

}
```


### Which Pocock calculation is faster?

```{r}
bench::mark(
  pocock_bounds(),
  pocock_bounds_ib(),
  check = FALSE
)
```

Interval bisection is faster.

### `of_bounds_ib()`

Get O'Brien-Fleming bounds with interval bisection.

```{r}
of_bounds_ib <- function(n_analyses = 3,
                          alpha = 0.05,
                          n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # starting upper bounds
  ub1 <- rep(0, length.out = n_analyses)
  lb1 <- -ub1
  
  # starting lower bounds
  ub2 <- rep(10, length.out = n_analyses)
  lb2 <- -ub2
  
  # ob bounds
  ob_u1 <- ub1 * (1:n_analyses / n_analyses)^-0.5
  ob_l1 <- -ob_u1
  
  ob_u2 <- ub2 * (1:n_analyses / n_analyses)^-0.5
  ob_l2 <- -ob_u2
  
  # first alpha calculation
  sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = ob_u1,
                            lower_bounds = ob_l1,
                            n_patients = n_patients)
  
  while ( abs(sim$alpha - alpha) > epsilon) {
    
    # calculate the first midpoint
    mid_u <- (ub1 + ub2) / 2
    mid_l <- -mid_u 
    
    # get ob bounds
    mid_ob_u <- mid_u * (1:n_analyses / n_analyses)^-0.5
    mid_ob_l <- -mid_ob_u
    
    # calculate the simulated alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = mid_ob_u,
                            lower_bounds = mid_ob_l,
                            n_patients = n_patients)
    
    # 
    if (sim$alpha > alpha) {
      
      ub1 <- mid_u
      lb1 <- mid_l
      
    } else {
      
      ub2 <- mid_u
      lb2 <- mid_l
      
    }
    
  } 
  
  # return the values of interest
  return( list(upper_bounds = mid_ob_u, 
               lower_bounds = mid_ob_l, 
               simulation = sim) )
  
}
```

```{r, eval=FALSE}
of_bounds_ib()
```

### `of_bounds()`

Get O'Brien-Fleming bounds with incremental steps.

```{r}
of_bounds <-  function(n_analyses = 3,
                       alpha = 0.05,
                       n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # close bounds using Bonferroni correction
  # -qnorm because the value of upper bounds must be positive
  bounds <- rep(-qnorm(alpha / n_analyses), length.out = n_analyses)
  
  # modify the bounds using OF multiple
  of_bounds <- bounds * (1:n_analyses / n_analyses)^-0.5
  
  # set the upper and lower bounds
  upper_bounds <- of_bounds
  lower_bounds <- -of_bounds
  
  # get alpha
  sim <- gsd_simulations(n_analyses = n_analyses,
                         upper_bounds = upper_bounds,
                         lower_bounds = lower_bounds,
                         n_patients = n_patients)
  
  # while the absolute value of the difference is larger than the precision
  while(abs(sim$alpha - alpha) >= epsilon) {
    
    # if we are above alpha, increase the magnitude of the bounds
    if( (sim$alpha - alpha) > epsilon) {
      
      bounds <- bounds + abs(sim$alpha - alpha)
  
    # if we are below alpha, decrease the magnitude of the bounds
    } else if ( (sim$alpha - alpha) < epsilon ) {
      
      bounds <- bounds - abs(sim$alpha - alpha)

    }
    
    # modify the bounds using OF multiple
    of_bounds <- bounds * (1:n_analyses / n_analyses)^-0.5
    
    # save the new bounds
    upper_bounds <- of_bounds
    lower_bounds <- -of_bounds
    
    # get the new value of alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                           upper_bounds = upper_bounds,
                           lower_bounds = lower_bounds,
                           n_patients = n_patients)
  }
  
  # return the values of interest
  return( list(upper_bounds = upper_bounds, 
               lower_bounds = lower_bounds, 
               simulation = sim) )

  
}
```

```{r}
of_bounds()
```

### Which O'Brien-Fleming calculation is faster?

```{r}
bench::mark(
  of_bounds(),
  of_bounds_ib(),
  check = FALSE
)
```

### `tri_bounds()`

```{r}
tri_bounds <- function(n_analyses = 3,
                       alpha = 0.05,
                       delta = 0.5) {
  
  I_L_term1 <- (4 * (0.583^2)) / n_analyses
  I_L_term2 <- 8 * log(1/(2*alpha))
  I_L_term3 <- (2 * 0.583) / sqrt(n_analyses)
  
  I_L <- (sqrt(I_L_term1 + I_L_term2) - I_L_term3)^2 * (1 / delta)^2
  
  bounds_term1 <- (2/delta) * log(1/(2*alpha))
  bounds_term2 <- 0.583 * sqrt(I_L / n_analyses)
  
  analysis_fracs <- (1:n_analyses / n_analyses)
  
  I_L_fracs <- I_L * analysis_fracs
  
  e_l <- (bounds_term1 - bounds_term2 + ((0.25*delta) * analysis_fracs * I_L )) / sqrt(I_L_fracs)

  f_l <- (-bounds_term1 + bounds_term2 + ((0.75*delta) * analysis_fracs * I_L )) / sqrt(I_L_fracs)
  
  return(list(upper_bounds = e_l, lower_bounds = f_l, info = I_L_fracs))
  
}
```


## Correct the bounds

In one-sided tests where the null is $\theta = 0$ and the alternative is $\theta > 0$, the final Pocock and O'Brien-Fleming bounds are set to be equal at the positive bound. For example, if the Pocock bounds are $\texttt{upper}=[2, 2, 2]$ and $\texttt{lower}=[-2, -2, -2]$, then the final bounds would be $\texttt{upper}=[2, 2, 2]$ and $\texttt{lower}=[-2, -2, 2]$. This needs to be implemented in the bounds calculations.

```{r}
pocock_bounds <- function(n_analyses = 3,
                          alpha = 0.05,
                          n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # starting upper bounds
  ub1 <- rep(0, length.out = n_analyses)
  lb1 <- -ub1
  
  # starting lower bounds
  ub2 <- rep(10, length.out = n_analyses)
  lb2 <- -ub2
  
  # first alpha calculation
  sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = ub1,
                            lower_bounds = lb1,
                            n_patients = n_patients)
  
  while ( abs(sim$alpha - alpha) > epsilon) {
    
    # calculate the first midpoint
    mid_u <- (ub1 + ub2) / 2
    mid_l <- -mid_u 
    
    # calculate the simulated alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = mid_u,
                            lower_bounds = mid_l,
                            n_patients = n_patients)
    
    # 
    if (sim$alpha > alpha) {
      
      ub1 <- mid_u
      lb1 <- mid_l
      
    } else {
      
      ub2 <- mid_u
      lb2 <- mid_l
      
    }
    
  } 
  
  # return the values of interest
  return( list(upper_bounds = ub1, 
               lower_bounds = c(lb1[1:n_analyses-1], ub1[n_analyses]), 
               simulation = sim) )
  
}
```

```{r}
of_bounds <- function(n_analyses = 3,
                          alpha = 0.05,
                          n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # starting upper bounds
  ub1 <- rep(0, length.out = n_analyses)
  lb1 <- -ub1
  
  # starting lower bounds
  ub2 <- rep(10, length.out = n_analyses)
  lb2 <- -ub2
  
  # ob bounds
  ob_u1 <- ub1 * (1:n_analyses / n_analyses)^-0.5
  ob_l1 <- -ob_u1
  
  ob_u2 <- ub2 * (1:n_analyses / n_analyses)^-0.5
  ob_l2 <- -ob_u2
  
  # first alpha calculation
  sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = ob_u1,
                            lower_bounds = ob_l1,
                            n_patients = n_patients)
  
  while ( abs(sim$alpha - alpha) > epsilon) {
    
    # calculate the first midpoint
    mid_u <- (ub1 + ub2) / 2
    mid_l <- -mid_u 
    
    # get ob bounds
    mid_ob_u <- mid_u * (1:n_analyses / n_analyses)^-0.5
    mid_ob_l <- -mid_ob_u
    
    # calculate the simulated alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                            upper_bounds = mid_ob_u,
                            lower_bounds = mid_ob_l,
                            n_patients = n_patients)
    
    # 
    if (sim$alpha > alpha) {
      
      ub1 <- mid_u
      lb1 <- mid_l
      
    } else {
      
      ub2 <- mid_u
      lb2 <- mid_l
      
    }
    
  } 
  
  # return the values of interest
  return( list(upper_bounds = mid_ob_u, 
               lower_bounds = c(mid_ob_l[1:n_analyses-1], mid_ob_u[n_analyses]), 
               simulation = sim) )
  
}
```

Test the functions.

```{r}
pocock_bounds()
of_bounds()
```

## Calculate ESS, VSS, and power

Calculate the boundaries.

```{r}
pocock_bounds <- pocock_bounds()
of_bounds <- of_bounds()
tri_bounds <- tri_bounds()
```

Get values for ESS, VSS, and power.

First, generate $\delta$ vector.

```{r}
deltas <- seq(from = 0, to = 1, by = 0.001)
```

### Pocock

```{r}
pk_power <- vector(mode = "numeric", length = length(deltas))
pk_ess <- vector(mode = "numeric", length = length(deltas))
pk_vss <- vector(mode = "numeric", length = length(deltas))

for (i in 1:length(deltas)) {
  
  sim <- gsd_simulations(upper_bounds = pocock_bounds$upper_bounds,
                         lower_bounds = pocock_bounds$lower_bounds,
                         alt_hypothesis = deltas[i])
  
  pk_power[i] <- sim$power
  pk_ess[i] <- sim$expected_sample_size
  pk_vss[i] <- sim$var_sample_size
}
```

### O'Brien-Fleming

```{r}
of_power <- vector(mode = "numeric", length = length(deltas))
of_ess <- vector(mode = "numeric", length = length(deltas))
of_vss <- vector(mode = "numeric", length = length(deltas))

for (i in 1:length(deltas)) {
  
  sim <- gsd_simulations(upper_bounds = of_bounds$upper_bounds,
                         lower_bounds = of_bounds$lower_bounds,
                         alt_hypothesis = deltas[i])
  
  of_power[i] <- sim$power
  of_ess[i] <- sim$expected_sample_size
  of_vss[i] <- sim$var_sample_size
}
```

### Triangular

```{r}
tr_power <- vector(mode = "numeric", length = length(deltas))
tr_ess <- vector(mode = "numeric", length = length(deltas))
tr_vss <- vector(mode = "numeric", length = length(deltas))

for (i in 1:length(deltas)) {
  
  sim <- gsd_simulations(upper_bounds = tri_bounds$upper_bounds,
                         lower_bounds = tri_bounds$lower_bounds,
                         alt_hypothesis = deltas[i])
  
  tr_power[i] <- sim$power
  tr_ess[i] <- sim$expected_sample_size
  tr_vss[i] <- sim$var_sample_size
  
}
```

### Plot the bounds

```{r}
ggplot() +
  geom_line(mapping = aes(x = 1:3, y = pocock_bounds$upper_bounds, color = "Pocock"),
            linetype = 2) +
  geom_line(mapping = aes(x = 1:3, y = pocock_bounds$lower_bounds, color = "Pocock"),
            linetype = 2) +
  geom_line(mapping = aes(x = 1:3, y = of_bounds$upper_bounds, color = "O'Brien-Fleming")) +
  geom_line(mapping = aes(x = 1:3, y = of_bounds$lower_bounds, color = "O'Brien-Fleming")) +
  geom_line(mapping = aes(x = 1:3, y = tri_bounds$upper_bounds, color = "Triangular")) +
  geom_line(mapping = aes(x = 1:3, y = tri_bounds$lower_bounds, color = "Triangular")) +
  scale_color_manual(name = "Boundary types",
                   breaks = c("Pocock", "O'Brien-Fleming", "Triangular"),
                   values = c("Pocock" = "red", 
                              "O'Brien-Fleming" = "blue", 
                              "Triangular" = "purple")) +
  labs(x = "Analysis Number", y = "Z score", 
       title = "Boundary values for different equations")
```


### ESS

```{r}
ggplot() + 
  geom_line(mapping = aes(x = deltas, y = pk_ess, color = "Pocock")) +
  geom_line(mapping = aes(x = deltas, y = of_ess, color = "O'Brien-Fleming")) +
  geom_line(mapping = aes(x = deltas, y = tr_ess, color = "Triangular")) +
  scale_color_manual(name = "Boundary types",
                     breaks = c("Pocock", "O'Brien-Fleming", "Triangular"),
                     values = c("Pocock" = "red", 
                                "O'Brien-Fleming" = "blue", 
                                "Triangular" = "purple")) +
  labs(x = "True \u03B4", y = "Expected sample size", 
       title = "Expected sample size over range of true \u03B4 values")
```


### VSS

```{r}
ggplot() + 
  geom_line(mapping = aes(x = deltas, y = sqrt(pk_vss), color = "Pocock")) +
  geom_line(mapping = aes(x = deltas, y = sqrt(of_vss), color = "O'Brien-Fleming")) +
  geom_line(mapping = aes(x = deltas, y = sqrt(tr_vss), color = "Triangular")) +
  scale_color_manual(name = "Boundary types",
                     breaks = c("Pocock", "O'Brien-Fleming", "Triangular"),
                     values = c("Pocock" = "red", 
                                "O'Brien-Fleming" = "blue", 
                                "Triangular" = "purple")) +
  labs(x = "True \u03B4", y = "Standard deviation of sample size", 
       title = "Standard deviation of sample size over range of true \u03B4 values")
```


### Power

```{r}
ggplot() +
  geom_line(mapping = aes(x = deltas, y = pk_power, color = "Pocock")) + 
  geom_line(mapping = aes(x = deltas, y = of_power, color = "O'Brien-Fleming")) + 
  geom_line(mapping = aes(x = deltas, y = tr_power, color = "Triangular")) +
  scale_color_manual(name = "Boundary types",
                     breaks = c("Pocock", "O'Brien-Fleming", "Triangular"),
                     values = c("Pocock" = "red",
                                "O'Brien-Fleming" = "blue",
                                "Triangular" = "purple")) +
  labs(x = "Alternative hypothesis = \u03B4", 
       y = "Power", 
       title = "Power for different boundaries")
```










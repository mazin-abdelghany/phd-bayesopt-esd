---
title: "GSD and GP regression - week 5"
output: 
  html_document:
    toc: true
    toc_depth: 4
    toc_float: 
      collapsed: false
date: "2025-11-13"
---

```{css, echo=FALSE}
#TOC {
    max-width: fit-content;
    white-space: nowrap;
}
  
div:has(> #TOC) {
    display: flex;
    flex-direction: row-reverse;
}
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# load required libraries
library(mvtnorm)
library(ggplot2)
library(profvis)

# set the seed
set.seed(20251113)
```

# GSD simulations

1. Design a trial, including boundaries
2. Obtain the characteristics of this trial
3. Estimate the expected sample size
4. Modify the sample size to obtain the correct power

The functions needed for the above steps are:

1. `triangular_bounds()`
2. `pocock_bounds()`
3. `ob_bounds()`
4. `gsd_simulations()`
5. `ess_simulations()`

All of these functions will need to be profiled.

## Interval bisection for boundaries

## Profile the code

| **Arguments**   | `gsd_simulations()` | `triangular_bounds()` | `pocock_bounds()` | `of_bounds()` | `getDesignGroupSequential()` | `getSampleSizeMeans()` |
|-----------------|:-------------------:|:---------------------:|:-----------------:|:-------------:|:----------------------------:|:----------------------:|
| n_analyses      |          x          |           x           |         x         |       x       |               x              |                        |
| alpha           |                     |           x           |         x         |       x       |               x              |                        |
| delta           |                     |           x           |                   |               |                              |                        |
| epsilon         |                     |                       |         x         |       x       |               x              |                        |
| n_patients      |          x          |                       |         x         |       x       |               x              |                        |
| null_hypothesis |          x          |                       |                   |               |                              |            x           |
| alt_hypothesis  |          x          |                       |                   |               |                              |            x           |
| variance        |          x          |                       |                   |               |                              |            x           |
| upper_bounds    |          x          |                       |                   |               |                              |            x           |
| lower_bounds    |          x          |                       |                   |               |                              |            x           |

### `gsd_simulations()`

```{r}
gsd_simulations <- function(n_analyses = 3,
                            upper_bounds = c(2.5, 2, 1.5),
                            lower_bounds = c(0, 0.75, 1.5),
                            n_patients = c(20, 40, 60),
                            null_hypothesis = 0,
                            alt_hypothesis = 0.5,
                            variance = 1) {
  
  # sanity checks
  # sanity checks, function stops
  if(length(upper_bounds) != length(lower_bounds)) {
    stop("Warning: number of upper bounds must equal number of lower bounds")
  }
  
  if(length(n_patients) != length(upper_bounds)) {
    stop("Warning: number of patients vector must equal number of bounds")
  }
  
  if(n_analyses != length(upper_bounds)) {
    stop("Warning: number of analyses must equal number of bounds")
  }
  
  # assign values for null and alt hypotheses
  theta_0 <- null_hypothesis
  delta <- alt_hypothesis
  
  # empty mean vectors to fill
  mean_0 <- c()
  mean_1 <- c()
  
  # need to parse the upper and lower boundaries of the design
  # for futility and efficacy, must put the bounds of integration correctly 
  # for pmvnorm
  futility_l_bounds <- list()
  futility_u_bounds <- list()
  efficacy_l_bounds <- list()
  efficacy_u_bounds <- list()

  n_analyses <- length(upper_bounds)

  for (i in 1:n_analyses) {
    
    # special case of i = 1
    if (i == 1) {
      futility_l_bounds[[i]] <- lower_bounds[i]
      futility_u_bounds[[i]] <- upper_bounds[i]
      efficacy_l_bounds[[i]] <- lower_bounds[i]
      efficacy_u_bounds[[i]] <- upper_bounds[i]
      next
    }
    
    # all other cases
    futility_l_bounds[[i]] <- c(lower_bounds[1:i-1], -Inf)
    futility_u_bounds[[i]] <- c(upper_bounds[1:i-1], lower_bounds[i])
    
    efficacy_l_bounds[[i]] <- c(lower_bounds[1:i-1], upper_bounds[i])
    efficacy_u_bounds[[i]] <- c(upper_bounds[1:i-1], Inf)
  }
  
  # list of probabilities to return
  probs_to_return <- list()
  
  # list of SIGMAs
  SIGMA_list <- list()
    
  for (i in 1:n_analyses) {
    if (i == 1) next
    
    # start with diagonal matrix for SIGMA
    SIGMA <- diag(nrow = i)
    
    # n = 2, need to fill all but 11, 22
    # n = 3, need to fill all but 11, 22, 33
    # n = 4, need to fill all but 11, 22, 33, 44
    # etc. 
    for(i in 1:i) {
      for(j  in 1:i) {
        
        # leave the 1s on the diagonal, skip this iteration of for loop
        if(i == j) next
        
        # when i is less than j, the lower number of patients will be in numerator
        if(i < j) SIGMA[i,j] <- sqrt(n_patients[i] / n_patients[j])
        
        # when i is greater than j, the lower number of patients will be in numerator
        if(i > j) SIGMA[i,j] <- sqrt(n_patients[j] / n_patients[i])
        
      }
    }
    
    SIGMA_list[[i]] <- SIGMA
  }
  
  
  for (i in 1:n_analyses) {
    
    ##############
    # ANALYSIS 1 #
    ##############
    if(i == 1) {
      # mean under null
      mean_0[i] <- theta_0 * sqrt(n_patients[i]/(2*variance))
      
      # mean under alternative
      mean_1[i] <- delta * sqrt(n_patients[i]/(2*variance))
      
      # prob stop for futility, null
      futility_null <- pnorm(futility_l_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance))
      
      # prob stop for efficacy, null
      efficacy_null <- pnorm(efficacy_u_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance), 
                             lower.tail = FALSE)
  
      # prob stop for futility, alt
      futility_alt <- pnorm(futility_l_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance))
      
      # prob stop for efficacy
      efficacy_alt <- pnorm(efficacy_u_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance), 
                            lower.tail = FALSE)
      
      probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
      names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
      
      next
    }
    
    ######################
    # ALL OTHER ANALYSES #
    ######################
    
    # next mean under null
    mean_0[i] <- theta_0 * sqrt(n_patients[i] / (2 * variance))
    
    # next mean under alternative
    mean_1[i] <- delta * sqrt(n_patients[i]/ (2*variance))
    
    # bounds for these will be same
    # futility under null
    futility_null <- pmvnorm(lower = futility_l_bounds[[i]], 
                             upper = futility_u_bounds[[i]], 
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    futility_alt <- pmvnorm(lower = futility_l_bounds[[i]], 
                            upper = futility_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    # bounds for these will be same
    # futility under null
    efficacy_null <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                             upper = efficacy_u_bounds[[i]],
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    efficacy_alt <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                            upper = efficacy_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
    names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
    
  }
    
  # vector to collect the sum of futility and efficacy probabilities
  sum_probs <- c()
  
  # get alpha and power
  alpha <- 0
  power <- 0
  
  for (i in 1:n_analyses) {
    
    # pull the probabilities from the list
    tmp_probs <- probs_to_return[[i]]
    
    # gather them into a vector
    # 3:4 because we want to calculate under the alternative
    sum_probs <- c(sum_probs, sum(tmp_probs[3:4]))
    
    alpha <- tmp_probs[2] + alpha
    power <- tmp_probs[4] + power
    
  }
  
  # calculate the expected sample size
  ess <- sum(n_patients * sum_probs)
  
  # add the expected sample size to the list
  return_values <- append(probs_to_return, values = c(ess, alpha, power))
  
  # name the list
  names_for_list <- as.vector(sapply("analysis_", paste0, 1:n_analyses))
  names_for_list <- c(names_for_list, "expected_sample_size", "alpha", "power")
  names(return_values) <- names_for_list
  
  # return probabilities and ESS
  return_values
}
```

```{r}
bench::mark(
  gsd_simulations()
)
```

```{r}
n_analyses = 3
upper_bounds = c(2.5, 2, 1.5)
lower_bounds = c(0, 0.75, 1.5)
n_patients = c(20, 40, 60)
null_hypothesis = 0
alt_hypothesis = 0.5
variance = 1

profvis({
  # assign values for null and alt hypotheses
  theta_0 <- null_hypothesis
  delta <- alt_hypothesis
  
  # empty mean vectors to fill
  mean_0 <- c()
  mean_1 <- c()
  
  # need to parse the upper and lower boundaries of the design
  # for futility and efficacy, must put the bounds of integration correctly 
  # for pmvnorm
  futility_l_bounds <- list()
  futility_u_bounds <- list()
  efficacy_l_bounds <- list()
  efficacy_u_bounds <- list()

  n_analyses <- length(upper_bounds)

  for (i in 1:n_analyses) {
    
    # special case of i = 1
    if (i == 1) {
      futility_l_bounds[[i]] <- lower_bounds[i]
      futility_u_bounds[[i]] <- upper_bounds[i]
      efficacy_l_bounds[[i]] <- lower_bounds[i]
      efficacy_u_bounds[[i]] <- upper_bounds[i]
      next
    }
    
    # all other cases
    futility_l_bounds[[i]] <- c(lower_bounds[1:i-1], -Inf)
    futility_u_bounds[[i]] <- c(upper_bounds[1:i-1], lower_bounds[i])
    
    efficacy_l_bounds[[i]] <- c(lower_bounds[1:i-1], upper_bounds[i])
    efficacy_u_bounds[[i]] <- c(upper_bounds[1:i-1], Inf)
  }
  
  # list of probabilities to return
  probs_to_return <- list()
  
  # list of SIGMAs
  SIGMA_list <- list()
    
  for (i in 1:n_analyses) {
    if (i == 1) next
    
    # start with diagonal matrix for SIGMA
    SIGMA <- diag(nrow = i)
    
    # n = 2, need to fill all but 11, 22
    # n = 3, need to fill all but 11, 22, 33
    # n = 4, need to fill all but 11, 22, 33, 44
    # etc. 
    for(i in 1:i) {
      for(j  in 1:i) {
        
        # leave the 1s on the diagonal, skip this iteration of for loop
        if(i == j) next
        
        # when i is less than j, the lower number of patients will be in numerator
        if(i < j) SIGMA[i,j] <- sqrt(n_patients[i] / n_patients[j])
        
        # when i is greater than j, the lower number of patients will be in numerator
        if(i > j) SIGMA[i,j] <- sqrt(n_patients[j] / n_patients[i])
        
      }
    }
    
    SIGMA_list[[i]] <- SIGMA
  }
  
  
  for (i in 1:n_analyses) {
    
    ##############
    # ANALYSIS 1 #
    ##############
    if(i == 1) {
      # mean under null
      mean_0[i] <- theta_0 * sqrt(n_patients[i]/(2*variance))
      
      # mean under alternative
      mean_1[i] <- delta * sqrt(n_patients[i]/(2*variance))
      
      # prob stop for futility, null
      futility_null <- pnorm(futility_l_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance))
      
      # prob stop for efficacy, null
      efficacy_null <- pnorm(efficacy_u_bounds[[i]], 
                             mean = mean_0, 
                             sd = sqrt(variance), 
                             lower.tail = FALSE)
  
      # prob stop for futility, alt
      futility_alt <- pnorm(futility_l_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance))
      
      # prob stop for efficacy
      efficacy_alt <- pnorm(efficacy_u_bounds[[i]], 
                            mean = mean_1, 
                            sd = sqrt(variance), 
                            lower.tail = FALSE)
      
      probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
      names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
      
      next
    }
    
    ######################
    # ALL OTHER ANALYSES #
    ######################
    
    # next mean under null
    mean_0[i] <- theta_0 * sqrt(n_patients[i] / (2 * variance))
    
    # next mean under alternative
    mean_1[i] <- delta * sqrt(n_patients[i]/ (2*variance))
    
    # bounds for these will be same
    # futility under null
    futility_null <- pmvnorm(lower = futility_l_bounds[[i]], 
                             upper = futility_u_bounds[[i]], 
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    futility_alt <- pmvnorm(lower = futility_l_bounds[[i]], 
                            upper = futility_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    # bounds for these will be same
    # futility under null
    efficacy_null <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                             upper = efficacy_u_bounds[[i]],
                             mean = mean_0, corr = SIGMA_list[[i]])
    # futility under alt
    efficacy_alt <- pmvnorm(lower = efficacy_l_bounds[[i]], 
                            upper = efficacy_u_bounds[[i]], 
                            mean = mean_1, corr = SIGMA_list[[i]])
    
    probs_to_return[[i]] <- c(futility_null, efficacy_null, futility_alt, efficacy_alt)
    names(probs_to_return[[i]]) <- c("futility_null", "efficacy_null", "futility_alt", "efficacy_alt")
    
  }
    
  # vector to collect the sum of futility and efficacy probabilities
  sum_probs <- c()
  
  # get alpha and power
  alpha <- 0
  power <- 0
  
  for (i in 1:n_analyses) {
    
    # pull the probabilities from the list
    tmp_probs <- probs_to_return[[i]]
    
    # gather them into a vector
    # 3:4 because we want to calculate under the alternative
    sum_probs <- c(sum_probs, sum(tmp_probs[3:4]))
    
    alpha <- tmp_probs[2] + alpha
    power <- tmp_probs[4] + power
    
  }
  
  # calculate the expected sample size
  ess <- sum(n_patients * sum_probs)
  
  # add the expected sample size to the list
  return_values <- append(probs_to_return, values = c(ess, alpha, power))
  
  # name the list
  names_for_list <- as.vector(sapply("analysis_", paste0, 1:n_analyses))
  names_for_list <- c(names_for_list, "expected_sample_size", "alpha", "power")
  names(return_values) <- names_for_list
})
```


### `triangular_bounds()`

```{r}
triangular_bounds <- function(n_analyses = 3,
                              alpha = 0.05,
                              delta = 0.5) {
  
  I_L_term1 <- (4 * (0.583^2)) / n_analyses
  I_L_term2 <- 8 * log(1/(2*alpha))
  I_L_term3 <- (2 * 0.583) / sqrt(n_analyses)
  
  I_L <- (sqrt(I_L_term1 + I_L_term2) - I_L_term3)^2 * (1 / delta)^2
  
  bounds_term1 <- (2/delta) * log(1/(2*alpha))
  bounds_term2 <- 0.583 * sqrt(I_L / n_analyses)
  
  analysis_fracs <- (1:n_analyses / n_analyses)
  
  I_L_fracs <- I_L * analysis_fracs
  
  e_l <- (bounds_term1 - bounds_term2 + ((0.25*delta) * analysis_fracs * I_L )) / sqrt(I_L_fracs)

  f_l <- (-bounds_term1 + bounds_term2 + ((0.75*delta) * analysis_fracs * I_L )) / sqrt(I_L_fracs)
  
  return(list(upper_bounds = e_l, lower_bounds = f_l, info = I_L_fracs))
  
}
```

```{r}
bench::mark(
  triangular_bounds(),
  min_iterations = 1e5
)
```

### `pocock_bounds()`

```{r}
pocock_bounds <- function(n_analyses = 3,
                             alpha = 0.05,
                             n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # close bounds using Bonferroni correction
  # -qnorm because the value of upper bounds must be positive
  bounds <- rep(-qnorm(alpha / n_analyses), length.out = n_analyses)
  
  # set the upper and lower bounds
  upper_bounds <- bounds
  lower_bounds <- -bounds
  
  # get alpha
  sim <- gsd_simulations(n_analyses = n_analyses,
                         upper_bounds = upper_bounds,
                         lower_bounds = lower_bounds,
                         n_patients = n_patients)
  
  # while the absolute value of the difference is larger than the precision
  while(abs(sim$alpha - alpha) > epsilon) {
    
    # if we are above alpha, increase the magnitude of the bounds
    if( (sim$alpha - alpha) > epsilon) {
      
      bounds <- bounds + abs(sim$alpha - alpha)
  
    # if we are below alpha, decrease the magnitude of the bounds
    } else if ( (sim$alpha - alpha) < epsilon ) {
      
      bounds <- bounds - abs(sim$alpha - alpha)

    }
    
    # save the new bounds
    upper_bounds <- bounds
    lower_bounds <- -bounds
    
    # get the new value of alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                           upper_bounds = upper_bounds,
                           lower_bounds = lower_bounds,
                           n_patients = n_patients)
  }
  
  # return the values of interest
  return( list(upper_bounds = upper_bounds, 
               lower_bounds = lower_bounds, 
               simulation = sim) )

}
```

```{r}
pocock_bounds()
```

```{r}
bench::mark(
  pocock_bounds()
)
```

### `ob_bounds()`

```{r}
ob_bounds <-  function(n_analyses = 3,
                       alpha = 0.05,
                       n_patients = c(20, 40, 60)) {
  
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # close bounds using Bonferroni correction
  # -qnorm because the value of upper bounds must be positive
  bounds <- rep(-qnorm(alpha / n_analyses), length.out = n_analyses)
  
  # modify the bounds using OF multiple
  of_bounds <- bounds * (1:n_analyses / n_analyses)^-0.5
  
  # set the upper and lower bounds
  upper_bounds <- of_bounds
  lower_bounds <- -of_bounds
  
  # get alpha
  sim <- gsd_simulations(n_analyses = n_analyses,
                         upper_bounds = upper_bounds,
                         lower_bounds = lower_bounds,
                         n_patients = n_patients)
  
  # while the absolute value of the difference is larger than the precision
  while(abs(sim$alpha - alpha) > epsilon) {
    
    # if we are above alpha, increase the magnitude of the bounds
    if( (sim$alpha - alpha) > epsilon) {
      
      bounds <- bounds + abs(sim$alpha - alpha)
  
    # if we are below alpha, decrease the magnitude of the bounds
    } else if ( (sim$alpha - alpha) < epsilon ) {
      
      bounds <- bounds - abs(sim$alpha - alpha)

    }
    
    # modify the bounds using OF multiple
    of_bounds <- bounds * (1:n_analyses / n_analyses)^-0.5
    
    # save the new bounds
    upper_bounds <- of_bounds
    lower_bounds <- -of_bounds
    
    # get the new value of alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                           upper_bounds = upper_bounds,
                           lower_bounds = lower_bounds,
                           n_patients = n_patients)
  }
  
  # return the values of interest
  return( list(upper_bounds = upper_bounds, 
               lower_bounds = lower_bounds, 
               simulation = sim) )

  
}
```

```{r}
ob_bounds()
```

```{r}
bench::mark(
  ob_bounds()
)
```

```{r}
n_analyses = 3
alpha = 0.05
n_patients = c(20, 40, 60)

profvis({
  # the precision of the estimate for alpha
  epsilon <- 1e-8
  
  # close bounds using Bonferroni correction
  # -qnorm because the value of upper bounds must be positive
  bounds <- rep(-qnorm(alpha / n_analyses), length.out = n_analyses)
  
  # modify the bounds using OF multiple
  of_bounds <- bounds * (1:n_analyses / n_analyses)^-0.5
  
  # set the upper and lower bounds
  upper_bounds <- of_bounds
  lower_bounds <- -of_bounds
  
  # get alpha
  sim <- gsd_simulations(n_analyses = n_analyses,
                         upper_bounds = upper_bounds,
                         lower_bounds = lower_bounds,
                         n_patients = n_patients)
  
  # while the absolute value of the difference is larger than the precision
  while(abs(sim$alpha - alpha) > epsilon) {
    
    # if we are above alpha, increase the magnitude of the bounds
    if( (sim$alpha - alpha) > epsilon) {
      
      bounds <- bounds + abs(sim$alpha - alpha)
  
    # if we are below alpha, decrease the magnitude of the bounds
    } else if ( (sim$alpha - alpha) < epsilon ) {
      
      bounds <- bounds - abs(sim$alpha - alpha)

    }
    
    # modify the bounds using OF multiple
    of_bounds <- bounds * (1:n_analyses / n_analyses)^-0.5
    
    # save the new bounds
    upper_bounds <- of_bounds
    lower_bounds <- -of_bounds
    
    # get the new value of alpha
    sim <- gsd_simulations(n_analyses = n_analyses,
                           upper_bounds = upper_bounds,
                           lower_bounds = lower_bounds,
                           n_patients = n_patients)
  }
})
```


### `max_ess()`

```{r}
max_ess <- function(gsd_simulator = gsd_simulations, 
                    epsilon = 0.0001,
                    delta1 = 0,
                    delta2 = 2) {
  
  while (abs(delta1 - delta2) > epsilon) {
    
    # calculate expected sample size
    ess1 <- gsd_simulations(alt_hypothesis = delta1)$expected_sample_size
    ess2 <- gsd_simulations(alt_hypothesis = delta2)$expected_sample_size
    
    # check conditions
    if (ess1 == ess2) {
  
      print("Reinitializing deltas...")
      delta1 <- 0
      delta2 <- delta2 + 0.3
    
    # if ess1 is larger, delta1 is closer to maximum, thus change delta2  
    } else if (ess1 > ess2) {
      
      delta2 <- (delta2 + delta1) / 2
    
    # if ess2 is larger, delta2 is closer to maximum, thus change delta1
    } else {
      
      delta1 <- (delta2 + delta1) / 2
      
    }
    
  }
  
  return(
    c(delta1 = delta1, 
      delta2 = delta2, 
      ess1 = ess1, 
      ess2 = ess2)
  )
}
```


```{r}
bench::mark(
  max_ess()
)
```

```{r}
epsilon = 0.0001
delta1 = 0
delta2 = 2

profvis({
    while (abs(delta1 - delta2) > epsilon) {
    
    # calculate expected sample size
    ess1 <- gsd_simulations(alt_hypothesis = delta1)$expected_sample_size
    ess2 <- gsd_simulations(alt_hypothesis = delta2)$expected_sample_size
    
    # check conditions
    if (ess1 == ess2) {
  
      print("Reinitializing deltas...")
      delta1 <- 0
      delta2 <- delta2 + 0.3
    
    # if ess1 is larger, delta1 is closer to maximum, thus change delta2  
    } else if (ess1 > ess2) {
      
      delta2 <- (delta2 + delta1) / 2
    
    # if ess2 is larger, delta2 is closer to maximum, thus change delta1
    } else {
      
      delta1 <- (delta2 + delta1) / 2
      
    }
    
  }
})
```



# GP regression
















